{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from skimage.feature import fisher_vector, ORB, learn_gmm\n",
    "import h5py\n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popatov_feat_extract(video_path):\n",
    "    '''A description of the video feature extraction used by Popatov et al on Category Specific video summarization. Which is described as SIFT feature extraction, PCA and Fisher model'''\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    all_descriptors = []\n",
    "    frame_count = 0\n",
    "    sift = cv2.SIFT_create() # Create the sift feature extracot\n",
    "    pca = PCA(n_components=64)\n",
    "    start = time.time()\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % 5 == 0:  # Process every 5th frame\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _,descriptors = sift.detectAndCompute(frame,None)\n",
    "            if descriptors is not None and descriptors.shape[0]>64:\n",
    "                all_descriptors.append(pca.fit_transform(descriptors))# Apply PCA to the SIFT features\n",
    "\n",
    "        frame_count += 1\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    print(all_descriptors[0].shape)\n",
    "    print(f'Time to read video detect sift and normalize: {end-start}')\n",
    "    k = 128\n",
    "    start = time.time()\n",
    "\n",
    "    gmm = learn_gmm(all_descriptors, n_modes=k)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Time to learn GMM  : {end-start}')\n",
    "    \n",
    "    def normalize(fisher_vector):\n",
    "        fisher_vector = (fisher_vector-np.mean(fisher_vector,axis=0))/(np.std(fisher_vector,axis=0))  #Mentioned \n",
    "        v = np.sqrt(abs(fisher_vector)) * np.sign(fisher_vector)\n",
    "        return v / np.sqrt(np.dot(v, v))\n",
    "    start = time.time()\n",
    "\n",
    "    fisher_vectors_array = np.array([normalize(fisher_vector(descriptor,gmm)) for descriptor in all_descriptors])\n",
    "    end = time.time()   \n",
    "    print(f'Time to create fishers : {end-start}')\n",
    "\n",
    "\n",
    "    return fisher_vectors_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_vector_arr = popatov_feat_extract(f'C:\\\\Users\\\\test\\\\Project-order\\\\Videos\\\\summe/video_10.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 64)\n",
      "Time to read video detect sift and normalize: 6.964510917663574\n",
      "Time to learn GMM  : 37.45828866958618\n",
      "Time to create fishers : 0.833204984664917\n",
      "(652, 64)\n",
      "Time to read video detect sift and normalize: 19.38700294494629\n",
      "Time to learn GMM  : 61.492006063461304\n",
      "Time to create fishers : 1.3966965675354004\n",
      "(314, 64)\n",
      "Time to read video detect sift and normalize: 14.765989065170288\n",
      "Time to learn GMM  : 45.25356435775757\n",
      "Time to create fishers : 0.7623374462127686\n",
      "(376, 64)\n",
      "Time to read video detect sift and normalize: 22.212496280670166\n",
      "Time to learn GMM  : 90.1943371295929\n",
      "Time to create fishers : 1.3633191585540771\n",
      "(11646, 64)\n",
      "Time to read video detect sift and normalize: 79.60613250732422\n",
      "Time to learn GMM  : 4094.601256608963\n",
      "Time to create fishers : 33.506054401397705\n",
      "(9532, 64)\n",
      "Time to read video detect sift and normalize: 35.70115327835083\n",
      "Time to learn GMM  : 3017.1729414463043\n",
      "Time to create fishers : 29.991528749465942\n",
      "(549, 64)\n",
      "Time to read video detect sift and normalize: 77.03356003761292\n",
      "Time to learn GMM  : 271.3270843029022\n",
      "Time to create fishers : 4.694077968597412\n",
      "(1313, 64)\n",
      "Time to read video detect sift and normalize: 21.65372323989868\n",
      "Time to learn GMM  : 302.0045862197876\n",
      "Time to create fishers : 4.768266201019287\n",
      "(1147, 64)\n",
      "Time to read video detect sift and normalize: 21.75329279899597\n",
      "Time to learn GMM  : 216.6708722114563\n",
      "Time to create fishers : 3.9491677284240723\n",
      "(15544, 64)\n",
      "Time to read video detect sift and normalize: 104.04304814338684\n",
      "Time to learn GMM  : 8880.531952619553\n",
      "Time to create fishers : 70.31859469413757\n"
     ]
    }
   ],
   "source": [
    "dataset_features = []\n",
    "summe_dataset = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "lengths  = [(summe_dataset[key]['n_frames'][...].item()) for key in list(summe_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(summe_dataset.keys())\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path = f'C:\\\\Users\\\\test\\\\Project-order\\\\Videos\\\\summe/{dataset_keys[index]}.mp4'\n",
    "    features = popatov_feat_extract(video_path)\n",
    "    dataset_features.append(features)\n",
    "np.save('Fishers_Features_summe.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpd_auto(K, ncp, vmax, desc_rate=1, **kwargs):\n",
    "    \"\"\"Main interface\n",
    "\n",
    "    Detect change points automatically selecting their number\n",
    "        K       - kernel between each pair of frames in video\n",
    "        ncp     - maximum ncp\n",
    "        vmax    - special parameter\n",
    "    Optional arguments:\n",
    "        lmin     - minimum segment length\n",
    "        lmax     - maximum segment length\n",
    "        desc_rate - rate of descriptor sampling (vmax always corresponds to 1x)\n",
    "\n",
    "    Note:\n",
    "        - cps are always calculated in subsampled coordinates irrespective to\n",
    "            desc_rate\n",
    "        - lmin and m should be in agreement\n",
    "    ---\n",
    "    Returns: (cps, costs)\n",
    "        cps   - best selected change-points\n",
    "        costs - costs for 0,1,2,...,m change-points\n",
    "\n",
    "    Memory requirement: ~ (3*N*N + N*ncp)*4 bytes ~= 16 * N^2 bytes\n",
    "    That is 1,6 Gb for the N=10000.\n",
    "    \"\"\"\n",
    "    m = ncp\n",
    "    (_, scores) = cpd_nonlin(K, m, backtrack=False, **kwargs)\n",
    "\n",
    "    N = K.shape[0]\n",
    "    N2 = N*desc_rate  # length of the video before subsampling\n",
    "\n",
    "    penalties = np.zeros(m+1)\n",
    "    # Prevent division by zero (in case of 0 changes)\n",
    "    ncp = np.arange(1, m+1)\n",
    "    penalties[1:] = (vmax*ncp/(2.0*N2))*(np.log(float(N2)/ncp)+1)\n",
    "\n",
    "    costs = scores/float(N) + penalties\n",
    "    m_best = np.argmin(costs)\n",
    "    (cps, scores2) = cpd_nonlin(K, m_best, **kwargs)\n",
    "\n",
    "    return (cps, scores2)\n",
    "\n",
    "\n",
    "#from scipy import weave\n",
    "\n",
    "def calc_scatters(K):\n",
    "    \"\"\"\n",
    "    Calculate scatter matrix:\n",
    "    scatters[i,j] = {scatter of the sequence with starting frame i and ending frame j}\n",
    "    \"\"\"\n",
    "    n = K.shape[0]\n",
    "    K1 = np.cumsum([0] + list(np.diag(K)))\n",
    "    K2 = np.zeros((n+1, n+1))\n",
    "    K2[1:, 1:] = np.cumsum(np.cumsum(K, 0), 1) # TODO: use the fact that K - symmetric\n",
    "\n",
    "    scatters = np.zeros((n, n))\n",
    "\n",
    "    diagK2 = np.diag(K2)\n",
    "\n",
    "    i = np.arange(n).reshape((-1,1))\n",
    "    j = np.arange(n).reshape((1,-1))\n",
    "    scatters = (K1[1:].reshape((1,-1))-K1[:-1].reshape((-1,1))\n",
    "                - (diagK2[1:].reshape((1,-1)) + diagK2[:-1].reshape((-1,1)) - K2[1:,:-1].T - K2[:-1,1:]) / ((j-i+1).astype(float) + (j==i-1).astype(float)))\n",
    "    scatters[j<i]=0\n",
    "    #code = r\"\"\"\n",
    "    #for (int i = 0; i < n; i++) {\n",
    "    #    for (int j = i; j < n; j++) {\n",
    "    #        scatters(i,j) = K1(j+1)-K1(i) - (K2(j+1,j+1)+K2(i,i)-K2(j+1,i)-K2(i,j+1))/(j-i+1);\n",
    "    #    }\n",
    "    #}\n",
    "    #\"\"\"\n",
    "    #weave.inline(code, ['K1','K2','scatters','n'], global_dict = \\\n",
    "    #    {'K1':K1, 'K2':K2, 'scatters':scatters, 'n':n}, type_converters=weave.converters.blitz)\n",
    "\n",
    "    return scatters\n",
    "\n",
    "def cpd_nonlin(K, ncp, lmin=1, lmax=100000, backtrack=True, verbose=True,\n",
    "    out_scatters=None):\n",
    "    \"\"\" Change point detection with dynamic programming\n",
    "    K - square kernel matrix\n",
    "    ncp - number of change points to detect (ncp >= 0)\n",
    "    lmin - minimal length of a segment\n",
    "    lmax - maximal length of a segment\n",
    "    backtrack - when False - only evaluate objective scores (to save memory)\n",
    "\n",
    "    Returns: (cps, obj)\n",
    "        cps - detected array of change points: mean is thought to be constant on [ cps[i], cps[i+1] )\n",
    "        obj_vals - values of the objective function for 0..m changepoints\n",
    "\n",
    "    \"\"\"\n",
    "    m = int(ncp)  # prevent numpy.int64\n",
    "\n",
    "    (n, n1) = K.shape\n",
    "    assert(n == n1), \"Kernel matrix awaited.\"\n",
    "\n",
    "    assert(n >= (m + 1)*lmin)\n",
    "    assert(n <= (m + 1)*lmax)\n",
    "    assert(lmax >= lmin >= 1)\n",
    "\n",
    "    if verbose:\n",
    "        #print \"n =\", n\n",
    "        print (\"Precomputing scatters...\")\n",
    "    J = calc_scatters(K)\n",
    "\n",
    "    if out_scatters != None:\n",
    "        out_scatters[0] = J\n",
    "\n",
    "    if verbose:\n",
    "        print (\"Inferring best change points...\")\n",
    "    # I[k, l] - value of the objective for k change-points and l first frames\n",
    "    I = 1e101*np.ones((m+1, n+1))\n",
    "    I[0, lmin:lmax] = J[0, lmin-1:lmax-1]\n",
    "\n",
    "    if backtrack:\n",
    "        # p[k, l] --- \"previous change\" --- best t[k] when t[k+1] equals l\n",
    "        p = np.zeros((m+1, n+1), dtype=int)\n",
    "    else:\n",
    "        p = np.zeros((1,1), dtype=int)\n",
    "\n",
    "    for k in range(1,m+1):\n",
    "        for l in range((k+1)*lmin, n+1):\n",
    "            tmin = max(k*lmin, l-lmax)\n",
    "            tmax = l-lmin+1\n",
    "            c = J[tmin:tmax,l-1].reshape(-1) + I[k-1, tmin:tmax].reshape(-1)\n",
    "            I[k,l] = np.min(c)\n",
    "            if backtrack:\n",
    "                p[k,l] = np.argmin(c)+tmin\n",
    "\n",
    "    #code = r\"\"\"\n",
    "    ##define max(x,y) ((x)>(y)?(x):(y))\n",
    "    #for (int k=1; k<m+1; k++) {\n",
    "    #    for (int l=(k+1)*lmin; l<n+1; l++) {\n",
    "    #        I(k, l) = 1e100; //nearly infinity\n",
    "    #        for (int t=max(k*lmin,l-lmax); t<l-lmin+1; t++) {\n",
    "    #            double c = I(k-1, t) + J(t, l-1);\n",
    "    #            if (c < I(k, l)) {\n",
    "    #                I(k, l) = c;\n",
    "    #                if (backtrack == 1) {\n",
    "    #                    p(k, l) = t;\n",
    "    #                }\n",
    "    #            }\n",
    "    #        }\n",
    "    #    }\n",
    "    #}\n",
    "    #\"\"\"\n",
    "\n",
    "    #weave.inline(code, ['m','n','p','I', 'J', 'lmin', 'lmax', 'backtrack'], \\\n",
    "    #    global_dict={'m':m, 'n':n, 'p':p, 'I':I, 'J':J, \\\n",
    "    #    'lmin':lmin, 'lmax':lmax, 'backtrack': int(1) if backtrack else int(0)},\n",
    "    #    type_converters=weave.converters.blitz)\n",
    "\n",
    "    # Collect change points\n",
    "    cps = np.zeros(m, dtype=int)\n",
    "\n",
    "    if backtrack:\n",
    "        cur = n\n",
    "        for k in range(m, 0, -1):\n",
    "            cps[k-1] = p[k, cur]\n",
    "            cur = cps[k-1]\n",
    "\n",
    "    scores = I[:, n].copy()\n",
    "    scores[scores > 1e99] = np.inf\n",
    "    return cps, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kts(n_frames,features,vmax=1, frame_skip = 1):\n",
    "      \"\"\" Receives the frame features from the CNN to do the Shot division based on KTS #TODO need to see how exactly this functions\n",
    "      \"\"\"\n",
    "      seq_len = len(features)\n",
    "      picks = np.arange(0, seq_len) * frame_skip\n",
    "\n",
    "      # compute change points using KTS\n",
    "      kernel = np.matmul(features, features.T)\n",
    "      change_points, _ = cpd_auto(kernel, seq_len - 1, vmax, verbose=False)\n",
    "      change_points *= frame_skip\n",
    "      change_points = np.hstack((0, change_points, n_frames))\n",
    "      begin_frames = change_points[:-1]\n",
    "      end_frames = change_points[1:]\n",
    "      change_points = np.vstack((begin_frames, end_frames - 1)).T\n",
    "\n",
    "      n_frame_per_seg = end_frames - begin_frames\n",
    "      return change_points, n_frame_per_seg, picks\n",
    "\n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n",
    "\n",
    "summe_dataset = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "\n",
    "lengths  = [(summe_dataset[key]['n_frames'][...].item()) for key in list(summe_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(summe_dataset.keys())\n",
    "\n",
    "\n",
    "fish_feat = np.load('Fishers_Features_summe.npy',allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kts(lengths[indices[0]],fish_feat[0],1,frame_skip=5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 16512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_feat[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i,feature \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(Fishers_features):\n\u001b[0;32m      5\u001b[0m     n_frames \u001b[39m=\u001b[39m lengths[indices[i]]\n\u001b[1;32m----> 6\u001b[0m     change_points,_ ,_\u001b[39m=\u001b[39m kts(n_frames,np\u001b[39m.\u001b[39marray(feature),vmax\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[0;32m      7\u001b[0m     shot_boundary\u001b[39m.\u001b[39mappend(change_points)\n\u001b[0;32m      8\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mFisher_shot_boundaries_summe.npy\u001b[39m\u001b[39m'\u001b[39m,np\u001b[39m.\u001b[39marray(shot_boundary, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m), allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kts' is not defined"
     ]
    }
   ],
   "source": [
    "Fishers_features= np.load('Fishers_Features_summe.npy',allow_pickle = True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=1.0)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_boundaries, predicted_boundaries):\n",
    "    TP = len(set(true_boundaries) & set(predicted_boundaries))\n",
    "    FP = len(set(predicted_boundaries) - set(true_boundaries))\n",
    "    FN = len(set(true_boundaries) - set(predicted_boundaries))\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "  \n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.02408578287737998\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(googlenet_f1_scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Fishers_features= np.load('Fishers_Features_summe.npy',allow_pickle = True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.02408578287737998\n",
      "Fisher average f1 : 0.02408578287737998\n",
      "Fisher average f1 : 0.02408578287737998\n",
      "Fisher average f1 : 0.02408578287737998\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "Fishcher_1_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_1_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_1_f1_scores)}')\n",
    "\n",
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "Fishcher_0_8_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_8_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_8_f1_scores)}')\n",
    "Fishcher_0_6_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_6_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_6_f1_scores)}')\n",
    "\n",
    "Fishcher_0_4_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_4_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_4_f1_scores)}')\n",
    "\n",
    "\n",
    "\n",
    "results_dict = {'Vmax 1.0 ':np.mean(Fishcher_1_f1_scores) , 'Vmax 0.8':np.mean(Fishcher_0_8_f1_scores),'Vmax 0.6':np.mean(Fishcher_0_6_f1_scores),'Vmax 0.4':np.mean(Fishcher_0_8_f1_scores)}\n",
    "\n",
    "json.dump(results_dict,open('Results/Fisher_Shot_boundary_results.json','w'),indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
