{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate the inconsistency in the Shot boundaries based on the CNN representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os \n",
    "from torchvision.models import resnet50, ResNet50_Weights,googlenet,GoogLeNet_Weights\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "from Utils import kts,calculate_metrics\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_path = \"Videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class THWC_to_CTHW(torch.nn.Module):\n",
    "    def forward(self, data):\n",
    "        # Do some transformations\n",
    "        return data.permute(3, 0, 1, 2)\n",
    "class PreProcessorVidSum(object):\n",
    "    def __init__(self,feature_extractor,target_downsample=2,shot_aware = True):\n",
    "        self.target_downsample = target_downsample\n",
    "        self.feature_extractor = feature_extractor # TODO add support for GPU\n",
    "        self.shot_aware = shot_aware\n",
    "    def run(self,video_path,shot_boundaries = []):\n",
    "        ''' This is using the shot boundaries from the h5 datasets to frames to pick the selected, so it returns all the frames features and the selected ones\n",
    "        '''\n",
    "        shot_boundaries = np.array(shot_boundaries).astype(int)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(frame_rate)\n",
    "        print(total_frames)\n",
    "        downsample_target = frame_rate//self.target_downsample if self.target_downsample!=0 else 1\n",
    "        picked_frames = np.arange(0,total_frames,downsample_target )\n",
    "        selected_frames = np.union1d(shot_boundaries,picked_frames)\n",
    "        print(len(selected_frames))\n",
    "        if selected_frames[-1]>total_frames-1: selected_frames[-1]=total_frames-1\n",
    "        print(selected_frames[-1],selected_frames[-2])\n",
    "        all_frames = []\n",
    "        for sub_frame in tqdm(selected_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,sub_frame)\n",
    "            ret,frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error reading frame at index {sub_frame}\")\n",
    "                continue\n",
    "            all_frames.append(self.feature_extractor.run(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))).numpy())\n",
    "        cap.release()\n",
    "        return all_frames, selected_frames\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self,model,transforms):\n",
    "        self.model = model\n",
    "        self.transforms = transforms # Transforms should act like one function, otherwise, one should do this outside and pass identity through this transform\n",
    "\n",
    "    def run(self,input):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # The model has to be in eval mode and on the GPU/CPU set outside.\n",
    "        with torch.no_grad():\n",
    "            return self.model(self.transforms(input).unsqueeze(0).to(device)).squeeze().to('cpu')\n",
    "        \n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summe_dataset = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "lengths  = [(summe_dataset[key]['n_frames'][...].item()) for key in list(summe_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(summe_dataset.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = googlenet(weights = GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "preprocess = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
    "\n",
    "submodel = nn.Sequential(*list(model.children())[:-2]).to(device).eval()\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(25):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'summe/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('GoogleNet_Features_summe.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5file = summe_dataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "submodel = nn.Sequential(*list(model.children())[:-1])\n",
    "submodel.eval().to(device)\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(25):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'summe/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('Resnet_Features_summe.npy',np.array(dataset_features, dtype=object), allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet121(weights =DenseNet121_Weights.IMAGENET1K_V1)\n",
    "submodel = nn.Sequential(*list(model.children())[:-1],nn.AdaptiveAvgPool2d(1)).to('cuda')\n",
    "\n",
    "processed_dataset = 'densnet'\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(25):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'summe/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('Densnet_Features_summe.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of Shot Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_features= np.load('GoogleNet_Features_summe.npy',allow_pickle = True)\n",
    "resnet_features = np.load('Resnet_Features_summe.npy',allow_pickle = True)\n",
    "densenet_features = np.load('Densnet_Features_summe.npy',allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.8_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.8_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.8_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.6_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.6_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.6_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.4_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.4_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.4_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fishers_features= np.load('Fishers_Features_summe.npy',allow_pickle = True)\n",
    "\n",
    "shot_boundary = []\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=1.0)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('googlenet_shot_boundaries_summe.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries_summe.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_summe.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results = {}\n",
    "resnet_results ={}\n",
    "densenet_results ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "googlenet_results['Vmax 1.0'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 1.0'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 1.0'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11500576460716297\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.13774717986131765\n",
      "resnet average f1 : 0.11034652746312465\n",
      "DenseNet average f1 : 0.1215005227419415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8 Vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.10201714940551831\n",
      "resnet average f1 : 0.09089453203378416\n",
      "DenseNet average f1 : 0.1215005227419415\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.8_summe.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.8_summe.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.8_summe.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.8'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.8'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.8'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11989786777833027\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.09233794170268375\n",
      "resnet average f1 : 0.07743198392249974\n",
      "DenseNet average f1 : 0.1215005227419415\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.6_summe.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.6_summe.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.6_summe.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11345499856805104\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.6'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.6'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.6'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.08213614840477737\n",
      "resnet average f1 : 0.07061977140682282\n",
      "DenseNet average f1 : 0.1215005227419415\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.4_summe.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.4_summe.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.4_summe.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12695281923192953\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.4'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.4'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.4'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(googlenet_results,open('Results/Googlenet_Shot_boundary_results.json','w'),indent=4)\n",
    "json.dump(resnet_results,open('Results/Resnet_Shot_boundary_results.json','w'),indent=4)\n",
    "json.dump(densenet_results,open('Results/Densenet_Shot_boundary_results.json','w'),indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
