{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to replicate the Shot boundaries using Popatov et als Procedure for the SumMe dataset\n",
    "\n",
    "The procedure followed listed verbatim from the paper is as follows:\n",
    "\n",
    "1. The video is sub-sampled by skipping every sth frame (s = 5),\n",
    "2. MultiScale SIFT  features are extracted and PCA is applied for dimen-\n",
    "sionality reduction, leading to a set of 64 features,\n",
    "3. For all of the sub-sampled frame features, a Gaussian Mixture Model is\n",
    "trained with 128 Gaussians,\n",
    "4. Finally, a Fisher vector  is extracted for each frame.\n",
    "\n",
    "This notebook should be run in environment 2 which uses python version 3.10. the full set of instructions to setup this environment can be seen in the Setup.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m fisher_vector, ORB, learn_gmm\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mUtils\u001b[39;00m \u001b[39mimport\u001b[39;00m calculate_metrics,kts\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProjMethSum\\VidSumMethods\\Utils\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdicts\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msummary_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mkts\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\ProjMethSum\\VidSumMethods\\Utils\\dicts.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m loss_dict \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mMSELoss,\u001b[39m\"\u001b[39m\u001b[39mHuber\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mHuberLoss,\u001b[39m\"\u001b[39m\u001b[39mCrossEntropy\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mCrossEntropyLoss,\u001b[39m'\u001b[39m\u001b[39mKLD\u001b[39m\u001b[39m'\u001b[39m:nn\u001b[39m.\u001b[39mKLDivLoss,\u001b[39m\"\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m\"\u001b[39m:nn\u001b[39m.\u001b[39mL1Loss}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from skimage.feature import fisher_vector, ORB, learn_gmm\n",
    "import h5py\n",
    "from Utils import calculate_metrics,kts\n",
    "import json\n",
    "import os\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    ''' This returns a list of indices sorted based on the values in the original array\n",
    "    '''\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n",
    "\n",
    "def popatov_feat_extract(video_path):\n",
    "    '''A description of the video feature extraction used by Popatov et al on Category Specific video summarization. Which is described as SIFT feature extraction, PCA and Fisher model'''\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    all_descriptors = []\n",
    "    frame_count = 0\n",
    "    sift = cv2.SIFT_create() # Create the sift feature extracot\n",
    "    pca = PCA(n_components=64)\n",
    "    start = time.time()\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % 5 == 0:  # Process every 5th frame\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _,descriptors = sift.detectAndCompute(frame,None)\n",
    "            if descriptors is not None and descriptors.shape[0]>64:\n",
    "                all_descriptors.append(pca.fit_transform(descriptors))# Apply PCA to the SIFT features\n",
    "\n",
    "        frame_count += 1\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    print(all_descriptors[0].shape)\n",
    "    print(f'Time to read video detect sift and normalize: {end-start}')\n",
    "    k = 128\n",
    "    start = time.time()\n",
    "\n",
    "    gmm = learn_gmm(all_descriptors, n_modes=k)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Time to learn GMM  : {end-start}')\n",
    "    \n",
    "    def normalize(fisher_vector):\n",
    "        fisher_vector = (fisher_vector-np.mean(fisher_vector,axis=0))/(np.std(fisher_vector,axis=0))  #Mentioned \n",
    "        v = np.sqrt(abs(fisher_vector)) * np.sign(fisher_vector)\n",
    "        return v / np.sqrt(np.dot(v, v))\n",
    "    start = time.time()\n",
    "\n",
    "    fisher_vectors_array = np.array([normalize(fisher_vector(descriptor,gmm)) for descriptor in all_descriptors])\n",
    "    end = time.time()   \n",
    "    print(f'Time to create fishers : {end-start}')\n",
    "\n",
    "\n",
    "    return fisher_vectors_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_path = \"Videos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional \n",
    "Run the Fisher Vector extractor and test if the array dimensionality matches that from Popatov et al (D = 16512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_vector_arr = popatov_feat_extract(os.path.join(video_dir_path,'/summe/video_10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = []\n",
    "summe_dataset = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "lengths  = [(summe_dataset[key]['n_frames'][...].item()) for key in list(summe_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(summe_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'summe/{dataset_keys[index]}.mp4')\n",
    "    features = popatov_feat_extract(video_path)\n",
    "    dataset_features.append(features)\n",
    "np.save('Fishers_Features_summe.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fishers_features= np.load('Fishers_Features_summe.npy',allow_pickle = True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=1.0,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.02408578287737998\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(googlenet_f1_scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Fishers_features= np.load('Fishers_Features_summe.npy',allow_pickle = True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe_0.6.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_summe_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.02408578287737998\n",
      "Fisher average f1 : 0.029868413386656946\n",
      "Fisher average f1 : 0.029868413386656946\n",
      "Fisher average f1 : 0.029868413386656946\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "Fishcher_1_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_1_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_1_f1_scores)}')\n",
    "\n",
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_summe.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_summe_0.8.npy',allow_pickle=True)\n",
    "Fishcher_0_8_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_8_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_8_f1_scores)}')\n",
    "Fishcher_0_6_f1_scores = []\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_summe_0.6.npy',allow_pickle=True)\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_6_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_6_f1_scores)}')\n",
    "\n",
    "Fishcher_0_4_f1_scores = []\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_summe_0.4.npy',allow_pickle=True)\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_4_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_4_f1_scores)}')\n",
    "\n",
    "\n",
    "\n",
    "results_dict = {'Vmax 1.0 ':np.mean(Fishcher_1_f1_scores) , 'Vmax 0.8':np.mean(Fishcher_0_8_f1_scores),'Vmax 0.6':np.mean(Fishcher_0_6_f1_scores),'Vmax 0.4':np.mean(Fishcher_0_8_f1_scores)}\n",
    "\n",
    "json.dump(results_dict,open('Results/Fisher_Shot_boundary_results.json','w'),indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
