{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate the inconsistency in the Shot boundaries based on the feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import os\n",
    "from torchvision.models import resnet50, ResNet50_Weights,googlenet,GoogLeNet_Weights\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "from Utils import kts,calculate_metrics\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_path = \"Videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n",
    "\n",
    "class THWC_to_CTHW(torch.nn.Module):\n",
    "    def forward(self, data):\n",
    "        # Do some transformations\n",
    "        return data.permute(3, 0, 1, 2)\n",
    "class PreProcessorVidSum(object):\n",
    "    def __init__(self,feature_extractor,target_downsample=2,shot_aware = True):\n",
    "        self.target_downsample = target_downsample\n",
    "        self.feature_extractor = feature_extractor # TODO add support for GPU\n",
    "        self.shot_aware = shot_aware\n",
    "    def run(self,video_path,shot_boundaries = []):\n",
    "        ''' This is using the shot boundaries from the h5 datasets to frames to pick the selected, so it returns all the frames features and the selected ones\n",
    "        '''\n",
    "        shot_boundaries = np.array(shot_boundaries).astype(int)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(frame_rate)\n",
    "        print(total_frames)\n",
    "        downsample_target = frame_rate//self.target_downsample if self.target_downsample!=0 else 1\n",
    "        picked_frames = np.arange(0,total_frames,downsample_target )\n",
    "        selected_frames = np.union1d(shot_boundaries,picked_frames)\n",
    "        print(len(selected_frames))\n",
    "        if selected_frames[-1]>total_frames-1: selected_frames[-1]=total_frames-1\n",
    "        print(selected_frames[-1],selected_frames[-2])\n",
    "        all_frames = []\n",
    "        for sub_frame in tqdm(selected_frames):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES,sub_frame)\n",
    "            ret,frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error reading frame at index {sub_frame}\")\n",
    "                continue\n",
    "            all_frames.append(self.feature_extractor.run(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))).numpy())\n",
    "        cap.release()\n",
    "        return all_frames, selected_frames\n",
    "\n",
    "class FeatureExtractor():\n",
    "    def __init__(self,model,transforms):\n",
    "        self.model = model\n",
    "        self.transforms = transforms # Transforms should act like one function, otherwise, one should do this outside and pass identity through this transform\n",
    "\n",
    "    def run(self,input):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # The model has to be in eval mode and on the GPU/CPU set outside.\n",
    "        with torch.no_grad():\n",
    "            return self.model(self.transforms(input).unsqueeze(0).to(device)).squeeze().to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsum_dataset = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "\n",
    "lengths  = [(tvsum_dataset[key]['n_frames'][...].item()) for key in list(tvsum_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(tvsum_dataset.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "2500\n",
      "2500\n",
      "2499 2498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 446/2500 [00:14<01:08, 29.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16884/1674448343.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mvideo_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_dir_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf'tvsum/{dataset_keys[index]}.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocesser_sum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mdataset_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16884/3232571707.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, video_path, shot_boundaries)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Error reading frame at index {sub_frame}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mall_frames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mall_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16884/3232571707.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# The model has to be in eval mode and on the GPU/CPU set outside.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mbranch1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mbranch2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mbranch3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mbranch4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\test\\GAN_KVDS\\venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1453\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1456\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = googlenet(weights = GoogLeNet_Weights.IMAGENET1K_V1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "preprocess = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
    "\n",
    "submodel = nn.Sequential(*list(model.children())[:-2]).to(device).eval()\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'tvsum/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('GoogleNet_Features_tvsum.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5file = tvsum_dataset\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "submodel = nn.Sequential(*list(model.children())[:-1])\n",
    "submodel.eval().to(device)\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'tvsum/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('Resnet_Features_tvsum.npy',np.array(dataset_features, dtype=object), allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = densenet121(weights =DenseNet121_Weights.IMAGENET1K_V1)\n",
    "submodel = nn.Sequential(*list(model.children())[:-1],nn.AdaptiveAvgPool2d(1)).to('cuda')\n",
    "\n",
    "processed_dataset = 'densnet'\n",
    "feature_extractor = FeatureExtractor(submodel,preprocess)\n",
    "preprocesser_sum = PreProcessorVidSum(feature_extractor,target_downsample=0)\n",
    "dataset_features = []\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path =os.path.join(video_dir_path,f'tvsum/{dataset_keys[index]}.mp4')\n",
    "    features,_ = preprocesser_sum.run(video_path)\n",
    "    dataset_features.append(features)\n",
    "\n",
    "\n",
    "\n",
    "np.save('Densnet_Features_tvsum.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of Shot Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_features= np.load('GoogleNet_Features_tvsum.npy',allow_pickle = True)\n",
    "resnet_features = np.load('Resnet_Features_tvsum.npy',allow_pickle = True)\n",
    "densenet_features = np.load('Densnet_Features_tvsum.npy',allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature))\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.6.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.6.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.6.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_boundary = []\n",
    "\n",
    "for feature in resnet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('resnet_shot_boundaries_vmax_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "\n",
    "for feature in googlenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('googlenet_shot_boundaries_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for feature in densenet_features:\n",
    "    feature = [feat/LA.norm(feat) for feat in feature]\n",
    "    n_frames = len(feature)\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('densenet_shot_boundaries_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "googlenet_shots = np.load('googlenet_shot_boundaries.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results = {}\n",
    "resnet_results ={}\n",
    "densenet_results ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2940]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densenet_shots[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  201],\n",
       "       [ 202,  311],\n",
       "       [ 312,  478],\n",
       "       [ 479,  666],\n",
       "       [ 667,  960],\n",
       "       [ 961, 1048],\n",
       "       [1049, 1124],\n",
       "       [1125, 1228],\n",
       "       [1229, 1350],\n",
       "       [1351, 1487],\n",
       "       [1488, 1624],\n",
       "       [1625, 1706],\n",
       "       [1707, 1794],\n",
       "       [1795, 1958],\n",
       "       [1959, 2241],\n",
       "       [2242, 2467],\n",
       "       [2468, 2499]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_shot_boundary[dataset_keys[indices[0]]]['change_points'][...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "googlenet_results['Vmax 1.0'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 1.0'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 1.0'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.4517452491313002\n",
      "resnet average f1 : 0.35952287214641804\n",
      "DenseNet average f1 : 0.08209442409442409\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8 Vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.39347434440659274\n",
      "resnet average f1 : 0.3168795153733152\n",
      "DenseNet average f1 : 0.08209442409442409\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.8.npy',allow_pickle=True)[10:20]\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.8.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.8.npy',allow_pickle=True)[20:30]\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25253413184825124\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.8'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.8'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.8'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.32693164649341244\n",
      "resnet average f1 : 0.2633254972947965\n",
      "DenseNet average f1 : 0.08209442409442409\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.6.npy',allow_pickle=True)[10:20]\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.6.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.6.npy',allow_pickle=True)[20:30]\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23142867232486375\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.6'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.6'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.6'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Googlenet average f1 : 0.2372799281259132\n",
      "resnet average f1 : 0.19722524250195686\n",
      "DenseNet average f1 : 0.08209442409442409\n"
     ]
    }
   ],
   "source": [
    "googlenet_shots = np.load('googlenet_shot_boundaries_0.4.npy',allow_pickle=True)\n",
    "resnet_shots = np.load('resnet_shot_boundaries_vmax_0.4.npy',allow_pickle=True)\n",
    "densenet_shots = np.load('densenet_shot_boundaries_0.4.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "resnet_f1_scores = []\n",
    "densenet_f1_scores = []\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),resnet_shots[i].flatten())\n",
    "    resnet_f1_scores.append(f1)\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),densenet_shots[i].flatten())\n",
    "    densenet_f1_scores.append(f1)\n",
    "\n",
    "\n",
    "print(f'Googlenet average f1 : {np.mean(googlenet_f1_scores)}')\n",
    "print(f'resnet average f1 : {np.mean(resnet_f1_scores)}')\n",
    "print(f'DenseNet average f1 : {np.mean(densenet_f1_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21228872323701808\n"
     ]
    }
   ],
   "source": [
    "perfs_avg = []\n",
    "for i in range(10):\n",
    "    _,_,f1_goog_res = calculate_metrics(resnet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    _,_,f1_res_dense= calculate_metrics(densenet_shots[i].flatten(),resnet_shots[i].flatten())\n",
    "    _,_,f1_dens_gog= calculate_metrics(densenet_shots[i].flatten(),googlenet_shots[i].flatten())\n",
    "    perfs_avg.append( np.mean([f1_goog_res,f1_res_dense]))\n",
    "print(np.mean(perfs_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_results['Vmax 0.4'] = np.mean(googlenet_f1_scores)\n",
    "resnet_results['Vmax 0.4'] = np.mean(resnet_f1_scores)\n",
    "densenet_results['Vmax 0.4'] = np.mean(densenet_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(googlenet_results,open('Results/Googlenet_Shot_boundary_results.json','w'),indent=4)\n",
    "json.dump(resnet_results,open('Results/Resnet_Shot_boundary_results.json','w'),indent=4)\n",
    "json.dump(densenet_results,open('Results/Densenet_Shot_boundary_results.json','w'),indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
