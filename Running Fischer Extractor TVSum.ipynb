{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to replicate the Shot boundaries using Popatov et als Procedure for the TVSum dataset\n",
    "\n",
    "The procedure followed listed verbatim from the paper is as follows:\n",
    "\n",
    "1. The video is sub-sampled by skipping every sth frame (s = 5),\n",
    "2. MultiScale SIFT  features are extracted and PCA is applied for dimensionality reduction, leading to a set of 64 features,\n",
    "3. For all of the sub-sampled frame features, a Gaussian Mixture Model is\n",
    "trained with 128 Gaussians,\n",
    "4. Finally, a Fisher vector  is extracted for each frame.\n",
    "\n",
    "This notebook should be run in environment 2 which uses python version 3.10. the full set of instructions to setup this environment can be seen in the Setup.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from skimage.feature import fisher_vector, ORB, learn_gmm\n",
    "import h5py\n",
    "from Utils import calculate_metrics,kts\n",
    "import json\n",
    "import skimage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the Scikit version matches 0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def g(seq):\n",
    "    # http://stackoverflow.com/questions/3382352/equivalent-of-numpy-argsort-in-basic-python/3383106#3383106\n",
    "    #lambda version by Tony Veijalainen\n",
    "    ''' This returns a list of indices sorted based on the values in the original array\n",
    "    '''\n",
    "    return [x for x,y in sorted(enumerate(seq), key = lambda x: x[1])]\n",
    "def popatov_feat_extract(video_path):\n",
    "    '''A description of the video feature extraction used by Popatov et al on Category Specific video summarization. Which is described as SIFT feature extraction, PCA and Fisher model'''\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    all_descriptors = []\n",
    "    frame_count = 0\n",
    "    sift = cv2.SIFT_create() # Create the sift feature extracot\n",
    "    pca = PCA(n_components=64)\n",
    "    start = time.time()\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        if frame_count % 5 == 0:  # Process every 5th frame\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _,descriptors = sift.detectAndCompute(frame,None)\n",
    "            if descriptors is not None and descriptors.shape[0]>64:\n",
    "                all_descriptors.append(pca.fit_transform(descriptors))# Apply PCA to the SIFT features\n",
    "\n",
    "        frame_count += 1\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    print(all_descriptors[0].shape)\n",
    "    print(f'Time to read video detect sift and normalize: {end-start}')\n",
    "    k = 128\n",
    "    start = time.time()\n",
    "\n",
    "    gmm = learn_gmm(all_descriptors, n_modes=k)\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Time to learn GMM  : {end-start}')\n",
    "    \n",
    "    def normalize(fisher_vector):\n",
    "        fisher_vector = (fisher_vector-np.mean(fisher_vector,axis=0))/(np.std(fisher_vector,axis=0))  #Mentioned \n",
    "        v = np.sqrt(abs(fisher_vector)) * np.sign(fisher_vector)\n",
    "        return v / np.sqrt(np.dot(v, v))\n",
    "    start = time.time()\n",
    "\n",
    "    fisher_vectors_array = np.array([normalize(fisher_vector(descriptor,gmm)) for descriptor in all_descriptors])\n",
    "    end = time.time()   \n",
    "    print(f'Time to create fishers : {end-start}')\n",
    "\n",
    "\n",
    "    return fisher_vectors_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_path = \"Videos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional \n",
    "Run the Fisher Vector extractor and test if the array dimensionality matches that from Popatov et al (D = 16512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_vector_arr = popatov_feat_extract(os.path.join(video_dir_path,'/tvsum/video_10.mp4'))\n",
    "fisher_vector_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Fisher Vectors over the dataset. We select 10 of the shortests videos due to time complexity of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = []\n",
    "_dataset = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "lengths  = [(_dataset[key]['n_frames'][...].item()) for key in list(_dataset.keys())]\n",
    "indices =g(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_keys = list(_dataset.keys())\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    video_path = os.path.join(video_dir_path,f'tvsum/{dataset_keys[index]}.mp4')\n",
    "    features = popatov_feat_extract(video_path)\n",
    "    dataset_features.append(features)\n",
    "np.save('Fishers_Features_tvsum.npy',np.array(dataset_features, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsum_dataset = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "lengths  = [(tvsum_dataset[key]['n_frames'][...].item()) for key in list(tvsum_dataset.keys())]\n",
    "indices =g(lengths)\n",
    "dataset_keys = list(tvsum_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform KTS Shot boundary Extraction using the extracted Fisher Features using the TVSum dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fishers_features= np.load('Fishers_Features_tvsum.npy',allow_pickle = True)\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=1.0,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_tvsum.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.8,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_0.8.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.6,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_0.6.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)\n",
    "shot_boundary = []\n",
    "for i,feature in enumerate(Fishers_features):\n",
    "    n_frames = lengths[indices[i]]\n",
    "    change_points,_ ,_= kts(n_frames,np.array(feature),vmax=0.4,frame_skip=5)\n",
    "    shot_boundary.append(change_points)\n",
    "np.save('Fisher_shot_boundaries_0.4.npy',np.array(shot_boundary, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score Evaluation\n",
    "\n",
    "Evaluating the F1 score between the Fisher Score Shot boundaries and the Shot boundaries provided by Zhang et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.029124814750446544\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "googlenet_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    googlenet_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(googlenet_f1_scores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shot boundary detection via Kernel Temporal Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher average f1 : 0.029124814750446544\n",
      "Fisher average f1 : 0.031326533496972335\n",
      "Fisher average f1 : 0.03132094448836527\n",
      "Fisher average f1 : 0.031315372863921824\n"
     ]
    }
   ],
   "source": [
    "gt_shot_boundary = h5py.File('Data/googlenet/googlenet_tvsum.h5')\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries.npy',allow_pickle=True)\n",
    "Fishcher_1_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_1_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_1_f1_scores)}')\n",
    "\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_0.8.npy',allow_pickle=True)\n",
    "Fishcher_0_8_f1_scores = []\n",
    "\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_8_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_8_f1_scores)}')\n",
    "Fishcher_0_6_f1_scores = []\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_0.6.npy',allow_pickle=True)\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_6_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_6_f1_scores)}')\n",
    "\n",
    "Fishcher_0_4_f1_scores = []\n",
    "googlenet_shots = np.load('Fisher_shot_boundaries_0.4.npy',allow_pickle=True)\n",
    "for i,index in enumerate(indices[:10]):\n",
    "    precison, recall, f1 = calculate_metrics(gt_shot_boundary[dataset_keys[index]]['change_points'][...].flatten(),googlenet_shots[i].flatten())\n",
    "    Fishcher_0_4_f1_scores.append(f1)\n",
    "print(f'Fisher average f1 : {np.mean(Fishcher_0_4_f1_scores)}')\n",
    "\n",
    "\n",
    "\n",
    "results_dict = {'Vmax 1.0 ':np.mean(Fishcher_1_f1_scores) , 'Vmax 0.8':np.mean(Fishcher_0_8_f1_scores),'Vmax 0.6':np.mean(Fishcher_0_6_f1_scores),'Vmax 0.4':np.mean(Fishcher_0_8_f1_scores)}\n",
    "\n",
    "json.dump(results_dict,open('Results/Fisher_Shot_boundary_results_tvsum.json','w'),indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
